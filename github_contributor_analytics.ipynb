{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf9bd56",
   "metadata": {},
   "source": [
    "# GitHub Contributor Analytics Pipeline\n",
    "\n",
    "End-to-end ingestion and transformation pipeline using GitHub REST API\n",
    "for the apache/airflow repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11364700",
   "metadata": {},
   "source": [
    "## Part 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b354dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed /repos/apache/airflow/pulls: 500\n",
      "\n",
      "Ingestion Complete — Row Counts:\n",
      "commits: 500\n",
      "pulls: 0\n",
      "pull_comments: 500\n",
      "issues: 500\n",
      "pull_reviews: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "OWNER = \"apache\"\n",
    "REPO = \"airflow\"\n",
    "\n",
    "# Optional but strongly recommended\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/vnd.github+json\"\n",
    "}\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    HEADERS[\"Authorization\"] = f\"Bearer {GITHUB_TOKEN}\"\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def fetch_paginated(endpoint, params=None, max_pages=5):\n",
    "    \"\"\"\n",
    "    Fetch paginated GitHub API data.\n",
    "    max_pages is used to control API usage.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page = 1\n",
    "\n",
    "    while page <= max_pages:\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}{endpoint}\",\n",
    "            headers=HEADERS,\n",
    "            params={**(params or {}), \"per_page\": 100, \"page\": page}\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed {endpoint}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        results.extend(data)\n",
    "        page += 1\n",
    "        time.sleep(0.5)  # polite rate limiting\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_json(filename, data):\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    row_counts = {}\n",
    "\n",
    "    # 1. Commits\n",
    "    commits = fetch_paginated(f\"/repos/{OWNER}/{REPO}/commits\")\n",
    "    row_counts[\"commits\"] = save_json(\"commits.json\", commits)\n",
    "\n",
    "    # 2. Pull Requests\n",
    "    pulls = fetch_paginated(f\"/repos/{OWNER}/{REPO}/pulls\", params={\"state\": \"all\"})\n",
    "    row_counts[\"pulls\"] = save_json(\"pulls.json\", pulls)\n",
    "\n",
    "    # 3. Pull Request Comments\n",
    "    pr_comments = fetch_paginated(f\"/repos/{OWNER}/{REPO}/pulls/comments\")\n",
    "    row_counts[\"pull_comments\"] = save_json(\"pull_comments.json\", pr_comments)\n",
    "\n",
    "    # 4. Issues (includes PRs — we’ll clean later)\n",
    "    issues = fetch_paginated(f\"/repos/{OWNER}/{REPO}/issues\", params={\"state\": \"all\"})\n",
    "    row_counts[\"issues\"] = save_json(\"issues.json\", issues)\n",
    "\n",
    "    # 5. Pull Reviews (sample first 20 PRs to stay safe)\n",
    "    pull_reviews = []\n",
    "    for pr in pulls[:20]:\n",
    "        pr_number = pr[\"number\"]\n",
    "        reviews = fetch_paginated(\n",
    "            f\"/repos/{OWNER}/{REPO}/pulls/{pr_number}/reviews\"\n",
    "        )\n",
    "        pull_reviews.extend(reviews)\n",
    "\n",
    "    row_counts[\"pull_reviews\"] = save_json(\"pull_reviews.json\", pull_reviews)\n",
    "\n",
    "    print(\"\\nIngestion Complete — Row Counts:\")\n",
    "    for k, v in row_counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8bfa0c",
   "metadata": {},
   "source": [
    "## Part 2: Contributor Analytics Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1883c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Contributors (by score):\n",
      "              author  score      tier  commits  prs  comments  reviews\n",
      "4             potiuk    100      core       22    0         0        0\n",
      "7           jscheffl    100      core       25    0         0        0\n",
      "27   dependabot[bot]    100      core       31    0         0        0\n",
      "23       amoghrajesh    100      core       24    0         0        0\n",
      "132     mistercrunch    100  observer        0    0       210        0\n",
      "46          vincbeck     95    active       19    0         0        0\n",
      "36    pierrejeambrun     95    active       19    0         0        0\n",
      "153       criccomini     94  observer        0    0        47        0\n",
      "55     jedcunningham     80    active       16    0         0        0\n",
      "32         henry3260     75    active       15    0         0        0\n",
      "\n",
      "Tier Distribution:\n",
      "tier\n",
      "contributor    99\n",
      "observer       43\n",
      "active         27\n",
      "core            4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary:\n",
      "Total contributors: 173\n",
      "Min score: 2\n",
      "Max score: 100\n",
      "Contributors with max score: 5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "def load_json(name):\n",
    "    with open(f\"{DATA_DIR}/{name}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# -------------------------------\n",
    "# Load datasets\n",
    "# -------------------------------\n",
    "commits = load_json(\"commits\")\n",
    "pulls = load_json(\"pulls\")\n",
    "comments = load_json(\"pull_comments\")\n",
    "reviews = load_json(\"pull_reviews\")\n",
    "\n",
    "metrics = defaultdict(lambda: {\n",
    "    \"commits\": 0,\n",
    "    \"prs\": 0,\n",
    "    \"comments\": 0,\n",
    "    \"reviews\": 0\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# Aggregate metrics\n",
    "# -------------------------------\n",
    "for c in commits:\n",
    "    author = c.get(\"commit\", {}).get(\"author\", {}).get(\"name\")\n",
    "    login = c.get(\"author\", {}).get(\"login\")\n",
    "    if login:\n",
    "        metrics[login][\"commits\"] += 1\n",
    "\n",
    "for p in pulls:\n",
    "    login = p.get(\"user\", {}).get(\"login\")\n",
    "    if login:\n",
    "        metrics[login][\"prs\"] += 1\n",
    "\n",
    "for c in comments:\n",
    "    login = c.get(\"user\", {}).get(\"login\")\n",
    "    if login:\n",
    "        metrics[login][\"comments\"] += 1\n",
    "\n",
    "for r in reviews:\n",
    "    login = r.get(\"user\", {}).get(\"login\")\n",
    "    if login:\n",
    "        metrics[login][\"reviews\"] += 1\n",
    "\n",
    "# -------------------------------\n",
    "# Create DataFrame\n",
    "# -------------------------------\n",
    "df = pd.DataFrame.from_dict(metrics, orient=\"index\").reset_index()\n",
    "df.rename(columns={\"index\": \"author\"}, inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Score\n",
    "# -------------------------------\n",
    "df[\"raw_score\"] = (\n",
    "    df[\"commits\"] * 5\n",
    "    + df[\"prs\"] * 10\n",
    "    + df[\"comments\"] * 2\n",
    "    + df[\"reviews\"] * 3\n",
    ")\n",
    "\n",
    "df[\"score\"] = df[\"raw_score\"].clip(upper=100)\n",
    "\n",
    "# -------------------------------\n",
    "# Tier assignment (ORDER MATTERS)\n",
    "# -------------------------------\n",
    "def assign_tier(row):\n",
    "    activity = row[\"commits\"] + row[\"prs\"]\n",
    "    if activity >= 20:\n",
    "        return \"core\"\n",
    "    elif activity >= 5:\n",
    "        return \"active\"\n",
    "    elif activity >= 1:\n",
    "        return \"contributor\"\n",
    "    else:\n",
    "        return \"observer\"\n",
    "\n",
    "df[\"tier\"] = df.apply(assign_tier, axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# Ranking\n",
    "# -------------------------------\n",
    "df = df.sort_values(\"score\", ascending=False)\n",
    "\n",
    "df[\"overall_rank\"] = df[\"score\"].rank(\n",
    "    method=\"dense\", ascending=False\n",
    ").astype(int)\n",
    "\n",
    "df[\"tier_rank\"] = (\n",
    "    df.groupby(\"tier\")[\"score\"]\n",
    "    .rank(method=\"dense\", ascending=False)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "df[\"percentile\"] = (df[\"score\"].rank(pct=True) * 100).round(2)\n",
    "\n",
    "# -------------------------------\n",
    "# Required Outputs\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\nTop 10 Contributors (by score):\")\n",
    "print(\n",
    "    df[\n",
    "        [\"author\", \"score\", \"tier\", \"commits\", \"prs\", \"comments\", \"reviews\"]\n",
    "    ].head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTier Distribution:\")\n",
    "print(df[\"tier\"].value_counts())\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total contributors: {len(df)}\")\n",
    "print(f\"Min score: {df['score'].min()}\")\n",
    "print(f\"Max score: {df['score'].max()}\")\n",
    "print(f\"Contributors with max score: {(df['score'] == 100).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e216a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"author\",\n",
    "        \"commits\",\n",
    "        \"prs\",\n",
    "        \"comments\",\n",
    "        \"reviews\",\n",
    "        \"score\",\n",
    "        \"tier\",\n",
    "        \"overall_rank\",\n",
    "        \"tier_rank\",\n",
    "        \"percentile\",\n",
    "    ]\n",
    "].to_csv(\"Part2_Contributors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d59df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
